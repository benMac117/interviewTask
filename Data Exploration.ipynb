{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and cleaning\n",
    "\n",
    "\n",
    "### First, I'll load the data and look at the first few entries\n",
    "* To create the list of types I first ran genfromtxt with *dtype=None* and then manually assigned types and string sizes\n",
    "* I'm ignoring the first column is this seems to be an index for the week of the year the sample was observed. It should be redundant when we have the date\n",
    "* I canâ€™t see a reason to include the year field for the same reason\n",
    "* I imagine the relationship with the date will have a strong non-linear element, i.e. when are avocados in season? I'm going to add another categorical feature for month to try to capture this\n",
    "* I gather that 4046, 4225, and 4770 are Hass avocado sizes\n",
    "  * I was thinking about removing the total volume, but the sum of the volumes for the three types does not equal the total\n",
    "    * I see the same characteristic with the bag size breakdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('2015-12-27', 1.33,  64236.62, 1036.74,  54454.85,  48.16, 8696.87, 8603.62,  93.25, 0., 'conventional', 'Albany'),\n",
       "       ('2015-12-20', 1.35,  54876.98,  674.28,  44638.81,  58.33, 9505.56, 9408.07,  97.49, 0., 'conventional', 'Albany'),\n",
       "       ('2015-12-13', 0.93, 118220.22,  794.7 , 109149.67, 130.5 , 8145.35, 8042.21, 103.14, 0., 'conventional', 'Albany')],\n",
       "      dtype=[('Date', 'S10'), ('AveragePrice', '<f8'), ('Total_Volume', '<f8'), ('4046', '<f8'), ('4225', '<f8'), ('4770', '<f8'), ('Total_Bags', '<f8'), ('Small_Bags', '<f8'), ('Large_Bags', '<f8'), ('XLarge_Bags', '<f8'), ('type', 'S20'), ('region', 'S20')])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filepath = '/home/ben/Data/morsum/avocado.csv'\n",
    "types = [\"|S10\", float, float, float, float, float, float, float, float, float, \"|S20\", \"|S20\"]\n",
    "columnsToIgnore = [0,12]\n",
    "rawData = np.genfromtxt(filepath, delimiter=',', usecols=np.setdiff1d(range(14), columnsToIgnore), dtype=types, names=True)\n",
    "rawData[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next I need to reformat some of the features for regression\n",
    "* This mostly means converting categorical features into one-hot vectors and converting the date to epoch time\n",
    "* I am performing this column by column but it may be more computationally efficient to go row by row\n",
    "* To minimise memory use I'm deleting columns from the raw data once they are no longer needed\n",
    "  *  If memory still became an issue I would need to look at not loading whole columns at once\n",
    "* I think there is maybe an argument for keeping the type column as a single feature {0,1} rather than converting it to one-hot, but I have more faith in not losing information this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# I would use datetime.timestamp if this was Python 3\n",
    "# I would consider doing this in two steps (conver to datetime, then to epoch), or in for loop\n",
    "epochDT = datetime(1970,1,1)\n",
    "reformattedData = np.array([((datetime.strptime(dataSample['Date'], '%Y-%m-%d')) - epochDT).total_seconds()\n",
    "                       for dataSample in rawData]).astype(int)\n",
    "monthColumn = np.array([dataSample['Date'].split('-')[1] for dataSample in rawData])\n",
    "\n",
    "# If I were doing this in production code I would use a one-hot helper function from the likes of SKLearn\n",
    "def convert_categorical_feature_to_onehot(categoricalFeatureVector, name=None):\n",
    "    \"\"\"Encodes a column of categorical features into one-hot vectors\"\"\"\n",
    "    categoryValues, categoryIndices = np.unique(categoricalFeatureVector, return_inverse=True)\n",
    "    # The np.eye function should generate a one-hot vector for each category\n",
    "    numCategories = len(categoryValues)\n",
    "    categoryOneHotOptions = np.eye(numCategories)\n",
    "    # I use the indices from 'return_inverse=True' to determine which category each sample is\n",
    "    if name is None:\n",
    "        return categoryOneHotOptions[categoryIndices]\n",
    "    return (categoryOneHotOptions[categoryIndices], [name+str(i) for i in range(numCategories)])\n",
    "\n",
    "# Convert months to one-hot vectors\n",
    "onehotMonths, monthLabels = convert_categorical_feature_to_onehot(monthColumn, 'month')\n",
    "reformattedData = np.append(reformattedData.reshape(-1,1), onehotMonths, axis=1) # Append month features\n",
    "\n",
    "rawData = rawData[list(rawData.dtype.names[1:])] # Remove date from raw data\n",
    "\n",
    "# The average price column is our target, I'm keeping it separate\n",
    "targetPrices = rawData['AveragePrice']\n",
    "rawData = rawData[list(rawData.dtype.names[1:])] # Remove prices from raw data\n",
    "\n",
    "# Some features are fine to add as they are\n",
    "simpleNumberFeatureNames = ['Total_Volume', '4046', '4225', '4770', 'Total_Bags','Small_Bags',\n",
    "                            'Large_Bags', 'XLarge_Bags']\n",
    "# The np.array(... .tolist()) here seems inefficient\n",
    "reformattedData = np.append(reformattedData, np.array(rawData[simpleNumberFeatureNames].tolist()), axis=1)\n",
    "# Remove standard features from raw data\n",
    "rawData = rawData[list(rawData.dtype.names[len(simpleNumberFeatureNames):])] \n",
    "\n",
    "# Adding the type column as one-hot vectors\n",
    "typeColumn, typeLabels = convert_categorical_feature_to_onehot(rawData['type'], 'type')\n",
    "reformattedData = np.append(reformattedData, typeColumn, axis=1)\n",
    "rawData = rawData[list(rawData.dtype.names[1:])] # Remove type from raw data\n",
    "\n",
    "# Adding the region column as one-hot vectors\n",
    "regionColumn, regionLabels = convert_categorical_feature_to_onehot(rawData['region'], 'region')\n",
    "reformattedData = np.append(reformattedData, regionColumn, axis=1)\n",
    "del rawData # This is the final feature, remove raw data object to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as .csv for analysis\n",
    "* The one-hot vectors have made this a more sparse feature set than I have used before\n",
    "* If I was not restricted in libraries I would like to visualise the data a little bit before moving on to machine learning\n",
    "  * Primarily, I would apply MDS to reduce the data to 2 dimensions, then plot them alongside the target price to get a feel for it. I would also see then if there are any large outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the target prices as the final column for easy separation later\n",
    "reformattedData = np.append(reformattedData, targetPrices.reshape(-1, 1), axis=1)\n",
    "\n",
    "# Assemble feature labels for header\n",
    "featureLabels = [['UNIXTime'], monthLabels, simpleNumberFeatureNames, typeLabels, regionLabels]\n",
    "flattenedLabels = [item for sublist in featureLabels for item in sublist]\n",
    "\n",
    "# Save data to CSV\n",
    "np.savetxt('/home/ben/Data/morsum/avocadoCleaned.csv', reformattedData, delimiter=',', \n",
    "           header=str(flattenedLabels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
